{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Ka1L0hl2Az98"
      },
      "id": "Ka1L0hl2Az98",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "gvZd-6ZOA55n"
      },
      "id": "gvZd-6ZOA55n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/Colab Notebooks/pharmahack23/\""
      ],
      "metadata": {
        "id": "6uhiVEy8A93J"
      },
      "id": "6uhiVEy8A93J",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "id": "3356093c",
      "metadata": {
        "id": "3356093c"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np  # linear algebra\n",
        "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import seaborn as sns\n",
        "import os\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
        "from sklearn.feature_selection import RFE, SelectKBest, chi2, SelectFromModel\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, matthews_corrcoef\n",
        "from sklearn.model_selection import LeaveOneOut, ShuffleSplit, cross_val_score\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "import lightgbm as lgb\n",
        "\n",
        "import random\n",
        "\n",
        "random_seed = 0\n",
        "\n",
        "def seed_everything(seed):\n",
        "    \"\"\"\"\n",
        "    Seed everything.\n",
        "    \"\"\"   \n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "#     torch.manual_seed(seed)\n",
        "#     torch.cuda.manual_seed(seed)\n",
        "#     torch.cuda.manual_seed_all(seed)\n",
        "#     torch.backends.cudnn.deterministic = True\n",
        "\n",
        "seed_everything(seed=random_seed)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hot Encoding And Min-Max Scaler"
      ],
      "metadata": {
        "id": "lleph-nqUbO5"
      },
      "id": "lleph-nqUbO5"
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "id": "781f46b4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "781f46b4",
        "outputId": "0e068b8b-6f1f-485a-8928-e0ebcd232682"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MinMaxScaler()"
            ],
            "text/html": [
              "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "df = pd.read_excel(path + \"train_data.xlsx\", sheet_name=\"x\")\n",
        "df_y = pd.read_excel(path + \"train_data.xlsx\", sheet_name=\"y\")\n",
        "df[\"y\"] = df_y[\"dd10 CM Content\"].values\n",
        "df.loc[df['y'] > 90, \"y_cat\"] = 1\n",
        "df.loc[df['y'] <= 90, \"y_cat\"] = 0\n",
        "\n",
        "df_y = df[\"y_cat\"]\n",
        "df.drop(labels=['y_cat', 'y'], axis=1, inplace=True)\n",
        "\n",
        "# df, df_y = smote.fit_resample(df, df_y)\n",
        "# print(df.shape, df_y.shape)\n",
        "\n",
        "\n",
        "# normalized df\n",
        "df_x = df\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensemble based Feature Selection; Taking common features among the 4 methods which is implemented as, \n",
        "\n",
        "1.   Pearson's correlation\n",
        "2.   Chi-Squared\n",
        "3.   Recursive Feature Elimination\n",
        "4.   Lasso\n",
        "\n"
      ],
      "metadata": {
        "id": "R4xZXvJtUjIx"
      },
      "id": "R4xZXvJtUjIx"
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "f8b0c407",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8b0c407",
        "outputId": "e5df56c0-cffa-41ec-c33f-56fb3acaf3a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50 selected features\n",
            "['dd1 Aggregate Size ', 'd1 Average pH Gradient', 'dd1 Lactate Concentration', 'Average DO concentration dd6', 'd0 Average pH Gradient', 'dd0-dd1 Aggregate Size Gradient', 'DO gradient/cell count dd1', 'Average DO concentration d1', 'dd5 Lactate Concentration', 'dd7 Glucose Concentration', 'dd5 DO 2nd derivative/cell count', 'dd5 Average of 2nd derivative DO', 'Average DO concentration dd7', 'DO concentration/cell count dd5', 'dd5 Aggregate Size ', 'dd0 Lactate Concentration', 'dd3 Average pH Gradient', 'Average DO concentration gradient dd5', 'dd7 Average pH Gradient', 'DO concentration/cell count dd2', 'dd7 Average pH', 'dd0-dd1 Cell Density Gradient', 'dd5 Glucose Concentration', 'DO concentration/cell count dd1', 'DO gradient/cell count dd0', 'dd3 Average of 2nd derivative DO', 'dd2-dd3 Cell Density Gradient', 'dd3 Lactate Concentration', 'Average DO concentration gradient dd1', 'dd3 DO 2nd derivative/cell count', 'Average DO concentration gradient dd0', 'dd3 Glucose Concentration', 'Presence of  IWP2 [h]', 'Preculture Time [h]', 'dd5-dd7 Cell Density Gradient', 'dd1 DO 2nd derivative/cell count', 'dd1 Average of 2nd derivative DO', 'Overall density gradient', 'Average DO concentration gradient d0', 'dd2 Cell Density', 'dd2-dd3 Aggregate Size Gradient', 'dd5 Average pH', 'dd2 Average pH', 'dd3 Aggregate Size ', 'dd2 Average pH Gradient', 'dd7 Cell Density', 'Average DO concentration gradient dd4', 'dd5-dd7 Aggregate Size Gradient', 'Start Preculture Perfusion [h after inoc] d1-d2', 'dd1 Cell Density']\n",
            "50 selected features\n",
            "['dd0 Cell Density', 'dd0-dd1 Cell Density Gradient', 'dd1 Cell Density', 'dd1-dd2 Cell Density Gradient', 'dd2 Cell Density', 'dd2-dd3 Cell Density Gradient', 'dd5-dd7 Cell Density Gradient', 'dd7 Cell Density', 'dd0-dd1 Aggregate Size Gradient', 'dd2-dd3 Aggregate Size Gradient', 'dd3 Aggregate Size ', 'dd3-dd5 Aggregate Size Gradient', 'dd5 Aggregate Size ', 'dd5-dd7 Aggregate Size Gradient', 'Preculture Time [h]', 'Start Preculture Perfusion [h after inoc] d1-d2', 'Presence of  IWP2 [h]', 'Average DO concentration dd5', 'Average DO concentration dd6', 'Average DO concentration dd7', 'Average DO concentration gradient d0', 'Average DO concentration gradient d1', 'Average DO concentration gradient dd0', 'Average DO concentration gradient dd1', 'Average DO concentration gradient dd4', 'Average DO concentration gradient dd5', 'DO concentration/cell count dd1', 'DO concentration/cell count dd2', 'DO concentration/cell count dd3', 'DO concentration/cell count dd5', 'DO gradient/cell count dd0', 'dd1 Average of 2nd derivative DO', 'dd3 Average of 2nd derivative DO', 'dd5 Average of 2nd derivative DO', 'dd1 DO 2nd derivative/cell count', 'dd3 DO 2nd derivative/cell count', 'dd5 DO 2nd derivative/cell count', 'Overall density gradient', 'dd2 Average pH', 'dd2 Average pH Gradient', 'dd5 Average pH', 'dd7 Average pH', 'dd7 Average pH Gradient', 'dd0 Lactate Concentration', 'dd1 Lactate Concentration', 'dd3 Lactate Concentration', 'dd5 Lactate Concentration', 'dd3 Glucose Concentration', 'dd5 Glucose Concentration', 'dd7 Glucose Concentration']\n",
            "Fitting estimator with 102 features.\n",
            "Fitting estimator with 92 features.\n",
            "Fitting estimator with 82 features.\n",
            "Fitting estimator with 72 features.\n",
            "Fitting estimator with 62 features.\n",
            "Fitting estimator with 52 features.\n",
            "50 selected features\n",
            "['dd1 Cell Density', 'dd1-dd2 Cell Density Gradient', 'dd2 Cell Density', 'dd2-dd3 Cell Density Gradient', 'dd5-dd7 Cell Density Gradient', 'dd7 Cell Density', 'dd0-dd1 Aggregate Size Gradient', 'dd2 Aggregate Size ', 'dd2-dd3 Aggregate Size Gradient', 'dd3 Aggregate Size ', 'dd5-dd7 Aggregate Size Gradient', 'Preculture Time [h]', 'Start Preculture Perfusion [h after inoc] d1-d2', 'Presence of  IWP2 [h]', 'Average DO concentration d1', 'Average DO concentration dd5', 'Average DO concentration dd6', 'Average DO concentration dd7', 'Average DO concentration gradient d0', 'Average DO concentration gradient d1', 'Average DO concentration gradient dd0', 'Average DO concentration gradient dd1', 'Average DO concentration gradient dd4', 'Average DO concentration gradient dd5', 'DO concentration/cell count dd2', 'DO concentration/cell count dd3', 'DO concentration/cell count dd5', 'DO gradient/cell count dd0', 'DO gradient/cell count dd5', 'DO gradient/cell count dd7', 'dd1 Average of 2nd derivative DO', 'dd3 Average of 2nd derivative DO', 'dd1 DO 2nd derivative/cell count', 'dd3 DO 2nd derivative/cell count', 'Overall density gradient', 'd1 Average pH', 'dd2 Average pH', 'dd2 Average pH Gradient', 'dd5 Average pH', 'dd6 Average pH Gradient', 'dd7 Average pH', 'dd7 Average pH Gradient', 'dd0 Lactate Concentration', 'dd3 Lactate Concentration', 'dd5 Lactate Concentration', 'dd7 Lactate Concentration', 'dd0 Glucose Concentration', 'dd3 Glucose Concentration', 'dd5 Glucose Concentration', 'dd7 Glucose Concentration']\n",
            "38 selected features\n",
            "['dd1 Cell Density', 'dd1-dd2 Cell Density Gradient', 'dd2 Cell Density', 'dd5-dd7 Cell Density Gradient', 'dd7 Cell Density', 'dd2 Aggregate Size ', 'dd2-dd3 Aggregate Size Gradient', 'dd3 Aggregate Size ', 'dd5-dd7 Aggregate Size Gradient', 'Start Preculture Perfusion [h after inoc] d1-d2', 'Presence of  IWP2 [h]', 'Average DO concentration dd6', 'Average DO concentration dd7', 'Average DO concentration gradient d0', 'Average DO concentration gradient d1', 'Average DO concentration gradient dd0', 'Average DO concentration gradient dd4', 'Average DO concentration gradient dd5', 'DO concentration/cell count dd5', 'DO gradient/cell count dd0', 'DO gradient/cell count dd5', 'DO gradient/cell count dd7', 'dd1 Average of 2nd derivative DO', 'dd3 Average of 2nd derivative DO', 'dd1 DO 2nd derivative/cell count', 'dd3 DO 2nd derivative/cell count', 'Overall density gradient', 'dd2 Average pH', 'dd2 Average pH Gradient', 'dd5 Average pH', 'dd7 Average pH', 'dd0 Lactate Concentration', 'dd3 Lactate Concentration', 'dd5 Lactate Concentration', 'dd7 Lactate Concentration', 'dd0 Glucose Concentration', 'dd3 Glucose Concentration', 'dd7 Glucose Concentration']\n",
            "40 selected features\n",
            "['dd0-dd1 Cell Density Gradient', 'dd1 Cell Density', 'dd2 Cell Density', 'dd3-dd5 Cell Density Gradient', 'dd5-dd7 Cell Density Gradient', 'dd7 Cell Density', 'dd1 Aggregate Size ', 'dd3 Aggregate Size ', 'dd7 Aggregate Size ', 'Presence of  IWP2 [h]', 'Average DO concentration d1', 'Average DO concentration dd7', 'Average DO concentration gradient d0', 'Average DO concentration gradient d1', 'Average DO concentration gradient dd2', 'Average DO concentration gradient dd4', 'Average DO concentration gradient dd5', 'DO concentration/cell count dd3', 'DO concentration/cell count dd7', 'DO gradient/cell count dd0', 'DO gradient/cell count dd5', 'dd1 Average of 2nd derivative DO', 'dd3 Average of 2nd derivative DO', 'dd0 DO 2nd derivative/cell count', 'dd1 DO 2nd derivative/cell count', 'dd3 DO 2nd derivative/cell count', 'dd7 DO 2nd derivative/cell count', 'Overall density gradient', 'd0 Average pH', 'd1 Average pH', 'd1 Average pH Gradient', 'dd2 Average pH', 'dd2 Average pH Gradient', 'dd4 Average pH', 'dd5 Average pH', 'dd0 Lactate Concentration', 'dd7 Lactate Concentration', 'dd0 Glucose Concentration', 'dd5 Glucose Concentration', 'dd7 Glucose Concentration']\n"
          ]
        }
      ],
      "source": [
        "#Pearson's correlation\n",
        "def cor_selector(X, y, num_feats):\n",
        "    cor_list = []\n",
        "    feature_name = X.columns.tolist()\n",
        "    # calculate the correlation with y for each feature\n",
        "    for i in X.columns.tolist():\n",
        "        cor = np.corrcoef(X[i], y)[0, 1]\n",
        "        cor_list.append(cor)\n",
        "    # replace NaN with 0\n",
        "    cor_list = [0 if np.isnan(i) else i for i in cor_list]\n",
        "    # feature name\n",
        "    cor_feature = X.iloc[:, np.argsort(np.abs(cor_list))[-num_feats:]].columns.tolist()\n",
        "    # feature selection? 0 for not select, 1 for select\n",
        "    cor_support = [True if i in cor_feature else False for i in feature_name]\n",
        "    return cor_support, cor_feature\n",
        "\n",
        "\n",
        "num_feats = 50\n",
        "cor_support, cor_feature = cor_selector(df_x, df_y, num_feats)\n",
        "print(str(len(cor_feature)), 'selected features')\n",
        "print(cor_feature)\n",
        "\n",
        "# Chi-Squared\n",
        "\n",
        "\n",
        "X_norm = MinMaxScaler().fit_transform(df_x)\n",
        "chi_selector = SelectKBest(chi2, k=num_feats)\n",
        "chi_selector.fit(X_norm, df_y)\n",
        "chi_support = chi_selector.get_support()\n",
        "chi_feature = df_x.loc[:, chi_support].columns.tolist()\n",
        "print(str(len(chi_feature)), 'selected features')\n",
        "print(chi_feature)\n",
        "\n",
        "# Recursive Feature Elimination\n",
        "\n",
        "\n",
        "rfe_selector = RFE(estimator=LogisticRegression(), n_features_to_select=num_feats, step=10, verbose=5)\n",
        "rfe_selector.fit(X_norm, df_y)\n",
        "rfe_support = rfe_selector.get_support()\n",
        "rfe_feature = df_x.loc[:, rfe_support].columns.tolist()\n",
        "print(str(len(rfe_feature)), 'selected features')\n",
        "print(rfe_feature)\n",
        "\n",
        "# Lasso: SelectFromModel\n",
        "\n",
        "embeded_lr_selector = SelectFromModel(LogisticRegression(penalty=\"l2\"), max_features=num_feats)\n",
        "embeded_lr_selector.fit(X_norm, df_y)\n",
        "\n",
        "embeded_lr_support = embeded_lr_selector.get_support()\n",
        "embeded_lr_feature = df_x.loc[:, embeded_lr_support].columns.tolist()\n",
        "print(str(len(embeded_lr_feature)), 'selected features')\n",
        "print(embeded_lr_feature)\n",
        "\n",
        "# Tree-based: SelectFromModel\n",
        "\n",
        "embeded_rf_selector = SelectFromModel(RandomForestClassifier(n_estimators=100), max_features=num_feats)\n",
        "embeded_rf_selector.fit(df_x, df_y)\n",
        "\n",
        "embeded_rf_support = embeded_rf_selector.get_support()\n",
        "embeded_rf_feature = df_x.loc[:, embeded_rf_support].columns.tolist()\n",
        "print(str(len(embeded_rf_feature)), 'selected features')\n",
        "print(embeded_rf_feature)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Selection ( Union and Intersection )"
      ],
      "metadata": {
        "id": "HGwHeGhgUsnZ"
      },
      "id": "HGwHeGhgUsnZ"
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "c9f78767",
      "metadata": {
        "id": "c9f78767"
      },
      "outputs": [],
      "source": [
        "total_feature = [cor_feature, chi_feature, rfe_feature, embeded_lr_feature]\n",
        "\n",
        "\n",
        "def intersect(*d):\n",
        "    sets = iter(map(set, d))\n",
        "    result = sets.next()\n",
        "    for s in sets:\n",
        "        result = result.intersection(s)\n",
        "    return result\n",
        "\n",
        "\n",
        "features_union = list(set(cor_feature + chi_feature + rfe_feature + embeded_lr_feature))\n",
        "features_intersection = list(set.intersection(*map(set, total_feature)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "id": "77766fc6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77766fc6",
        "outputId": "f511789c-ffde-4256-aede-18cbbee93cec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(42, 31) (42,) (18, 31) (18,)\n"
          ]
        }
      ],
      "source": [
        "intersec = True\n",
        "if intersec:\n",
        "    features = features_intersection\n",
        "else:\n",
        "    features = features_union\n",
        "\n",
        "df_train_x = pd.read_excel(path + \"train_data.xlsx\", sheet_name=\"x\")\n",
        "\n",
        "df_train_y = pd.read_excel(path + \"train_data.xlsx\", sheet_name=\"y\")\n",
        "df_train_x[\"y\"] = df_train_y[\"dd10 CM Content\"].values\n",
        "df_train_x.loc[df_train_x['y'] > 90, \"y_cat\"] = 1\n",
        "df_train_x.loc[df_train_x['y'] <= 90, \"y_cat\"] = 0\n",
        "\n",
        "df_train_y = df_train_x[\"y_cat\"]\n",
        "df_train_x.drop(labels=['y_cat', 'y'], axis=1, inplace=True)\n",
        "\n",
        "# df_train_x, df_train_y = smote.fit_resample(df_train_x, df_train_y)\n",
        "# print(df_train_x.shape, df_train_y.shape)\n",
        "\n",
        "\n",
        "df_train_x = df_train_x[features]\n",
        "\n",
        "# normalized df\n",
        "scaler = MinMaxScaler()\n",
        "df_tr = df_train_x\n",
        "scaler.fit(df_tr)\n",
        "df_train_x = scaler.transform(df_train_x)\n",
        "\n",
        "df_test_x = pd.read_excel(path + \"test_data_corrected.xlsx\", sheet_name=\"x\")\n",
        "df_test_y = pd.read_excel(path + \"test_data_corrected.xlsx\", sheet_name=\"y\")\n",
        "df_test_x[\"y\"] = df_test_y[\"dd10 CM Content\"].values\n",
        "df_test_x.loc[df_test_x['y'] > 90, \"y_cat\"] = 1\n",
        "df_test_x.loc[df_test_x['y'] <= 90, \"y_cat\"] = 0\n",
        "\n",
        "df_test_y = df_test_x[\"y_cat\"]\n",
        "df_test_x.drop(labels=['y_cat', 'y'], axis=1, inplace=True)\n",
        "# normalized df\n",
        "\n",
        "df_test_x = df_test_x[features]\n",
        "\n",
        "df_test_x = scaler.transform(df_test_x)\n",
        "\n",
        "print(df_train_x.shape, df_train_y.shape, df_test_x.shape, df_test_y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Leave One Out Implementation"
      ],
      "metadata": {
        "id": "csWcZzzcU8_U"
      },
      "id": "csWcZzzcU8_U"
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "52328679",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52328679",
        "outputId": "eed93cfb-77d9-47aa-fc8c-a3464a9aa27c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ],
      "source": [
        "loo = LeaveOneOut()\n",
        "loo.get_n_splits(df_train_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "fcfa64dc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcfa64dc",
        "outputId": "7ea48bf7-f6d6-4740-f458-87b9a236c5d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#######################################################################\n",
            "######################STANDALONE MACHINE LEARNING MODELS###############\n",
            "#######################################################################\n",
            "Test Accuracy score for LogisticRegression on Best LOO 0.556\n",
            "Test Precision score for LogisticRegression on Best LOO 0.385\n",
            "Test Recall score for LogisticRegression on Best LOO 1.0\n",
            "MCC score for LogisticRegression on Best LOO 0.385\n",
            "\n",
            "Test Accuracy score for SVC on Best LOO 0.611\n",
            "Test Precision score for SVC on Best LOO 0.4\n",
            "Test Recall score for SVC on Best LOO 0.8\n",
            "MCC score for SVC on Best LOO 0.305\n",
            "\n",
            "Test Accuracy score for GaussianNB on Best LOO 0.333\n",
            "Test Precision score for GaussianNB on Best LOO 0.294\n",
            "Test Recall score for GaussianNB on Best LOO 1.0\n",
            "MCC score for GaussianNB on Best LOO 0.15\n",
            "\n",
            "Test Accuracy score for MultinomialNB on Best LOO 0.667\n",
            "Test Precision score for MultinomialNB on Best LOO 0.4\n",
            "Test Recall score for MultinomialNB on Best LOO 0.4\n",
            "MCC score for MultinomialNB on Best LOO 0.169\n",
            "\n",
            "Test Accuracy score for SGDClassifier on Best LOO 0.611\n",
            "Test Precision score for SGDClassifier on Best LOO 0.417\n",
            "Test Recall score for SGDClassifier on Best LOO 1.0\n",
            "MCC score for SGDClassifier on Best LOO 0.439\n",
            "\n",
            "Test Accuracy score for KNeighborsClassifier on Best LOO 0.444\n",
            "Test Precision score for KNeighborsClassifier on Best LOO 0.273\n",
            "Test Recall score for KNeighborsClassifier on Best LOO 0.6\n",
            "MCC score for KNeighborsClassifier on Best LOO -0.014\n",
            "\n",
            "Test Accuracy score for DecisionTreeClassifier on Best LOO 0.778\n",
            "Test Precision score for DecisionTreeClassifier on Best LOO 0.571\n",
            "Test Recall score for DecisionTreeClassifier on Best LOO 0.8\n",
            "MCC score for DecisionTreeClassifier on Best LOO 0.523\n",
            "\n",
            "#######################################################################\n",
            "######################ENSEMBLE BASED LEARNING MODELS##################\n",
            "#######################################################################\n",
            "Test Accuracy score for RandomForestClassifier on Best LOO 0.944\n",
            "Test Precision score for RandomForestClassifier on Best LOO 0.833\n",
            "Test Recall score for RandomForestClassifier on Best LOO 1.0\n",
            "MCC score for RandomForestClassifier on Best LOO 0.877\n",
            "\n",
            "Test Accuracy score for GradientBoostingClassifier on Best LOO 0.667\n",
            "Test Precision score for GradientBoostingClassifier on Best LOO 0.429\n",
            "Test Recall score for GradientBoostingClassifier on Best LOO 0.6\n",
            "MCC score for GradientBoostingClassifier on Best LOO 0.269\n",
            "\n",
            "Test Accuracy score for XGBClassifier on Best LOO 0.944\n",
            "Test Precision score for XGBClassifier on Best LOO 0.833\n",
            "Test Recall score for XGBClassifier on Best LOO 1.0\n",
            "MCC score for XGBClassifier on Best LOO 0.877\n",
            "\n",
            "Test Accuracy score for AdaBoostClassifier on Best LOO 0.833\n",
            "Test Precision score for AdaBoostClassifier on Best LOO 0.75\n",
            "Test Recall score for AdaBoostClassifier on Best LOO 0.6\n",
            "MCC score for AdaBoostClassifier on Best LOO 0.564\n",
            "\n",
            "Test Accuracy score for LGBMClassifier on Best LOO 0.833\n",
            "Test Precision score for LGBMClassifier on Best LOO 0.75\n",
            "Test Recall score for LGBMClassifier on Best LOO 0.6\n",
            "MCC score for LGBMClassifier on Best LOO 0.564\n",
            "\n",
            "Test Accuracy score for VotingClassifier on Best LOO 0.667\n",
            "Test Precision score for VotingClassifier on Best LOO 0.429\n",
            "Test Recall score for VotingClassifier on Best LOO 0.6\n",
            "MCC score for VotingClassifier on Best LOO 0.269\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"#######################################################################\")\n",
        "print(\"######################STANDALONE MACHINE LEARNING MODELS###############\")\n",
        "print(\"#######################################################################\")\n",
        "\n",
        "\n",
        "\n",
        "avg_accuracy = []\n",
        "avg_mcc = []\n",
        "list_of_models = []\n",
        "for i, (train_index, test_index) in enumerate(loo.split(df_train_x)):\n",
        "    lr = LogisticRegression(random_state=random_seed, class_weight=\"balanced\")\n",
        "    lr.fit(df_train_x[train_index], df_train_y[train_index])\n",
        "    y_pred_lr = lr.predict(df_train_x[test_index])\n",
        "\n",
        "    avg_accuracy.append(accuracy_score(df_train_y[test_index], y_pred_lr))\n",
        "    avg_mcc.append(matthews_corrcoef(df_train_y[test_index], y_pred_lr))\n",
        "    list_of_models.append(lr)\n",
        "\n",
        "max_acc_index = avg_accuracy.index(max(avg_accuracy))\n",
        "y_pred_lr = list_of_models[max_acc_index].predict(df_test_x)\n",
        "print(\"Test Accuracy score for LogisticRegression on Best LOO\", round(accuracy_score(df_test_y, y_pred_lr), 3))\n",
        "print(\"Test Precision score for LogisticRegression on Best LOO\", round(precision_score(df_test_y, y_pred_lr), 3))\n",
        "print(\"Test Recall score for LogisticRegression on Best LOO\", round(recall_score(df_test_y, y_pred_lr), 3))\n",
        "\n",
        "print(\"MCC score for LogisticRegression on Best LOO\", round(matthews_corrcoef(df_test_y, y_pred_lr), 3))\n",
        "print()\n",
        "\n",
        "avg_accuracy = []\n",
        "avg_mcc = []\n",
        "list_of_models = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(loo.split(df_train_x)):\n",
        "    svc = SVC(random_state=random_seed, degree=25, class_weight=\"balanced\")\n",
        "    svc.fit(df_train_x[train_index], df_train_y[train_index])\n",
        "    y_pred_svc = svc.predict(df_train_x[test_index])\n",
        "\n",
        "    avg_accuracy.append(accuracy_score(df_train_y[test_index], y_pred_svc))\n",
        "    avg_mcc.append(matthews_corrcoef(df_train_y[test_index], y_pred_svc))\n",
        "    list_of_models.append(svc)\n",
        "\n",
        "max_acc_index = avg_accuracy.index(max(avg_accuracy))\n",
        "y_pred_svc = list_of_models[max_acc_index].predict(df_test_x)\n",
        "print(\"Test Accuracy score for SVC on Best LOO\", round(accuracy_score(df_test_y, y_pred_svc), 3))\n",
        "print(\"Test Precision score for SVC on Best LOO\", round(precision_score(df_test_y, y_pred_svc), 3))\n",
        "print(\"Test Recall score for SVC on Best LOO\", round(recall_score(df_test_y, y_pred_svc), 3))\n",
        "print(\"MCC score for SVC on Best LOO\", round(matthews_corrcoef(df_test_y, y_pred_svc), 3))\n",
        "print()\n",
        "\n",
        "avg_accuracy = []\n",
        "avg_mcc = []\n",
        "list_of_models = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(loo.split(df_train_x)):\n",
        "    gnb = GaussianNB()\n",
        "    gnb.fit(df_train_x[train_index], df_train_y[train_index])\n",
        "    y_pred_gnb = gnb.predict(df_train_x[test_index])\n",
        "\n",
        "    avg_accuracy.append(accuracy_score(df_train_y[test_index], y_pred_gnb))\n",
        "    avg_mcc.append(matthews_corrcoef(df_train_y[test_index], y_pred_gnb))\n",
        "    list_of_models.append(gnb)\n",
        "\n",
        "max_acc_index = avg_accuracy.index(max(avg_accuracy))\n",
        "y_pred_gnb = list_of_models[max_acc_index].predict(df_test_x)\n",
        "\n",
        "print(\"Test Accuracy score for GaussianNB on Best LOO\", round(accuracy_score(df_test_y, y_pred_gnb), 3))\n",
        "print(\"Test Precision score for GaussianNB on Best LOO\", round(precision_score(df_test_y, y_pred_gnb), 3))\n",
        "print(\"Test Recall score for GaussianNB on Best LOO\", round(recall_score(df_test_y, y_pred_gnb), 3))\n",
        "print(\"MCC score for GaussianNB on Best LOO\", round(matthews_corrcoef(df_test_y, y_pred_gnb), 3))\n",
        "print()\n",
        "\n",
        "avg_accuracy = []\n",
        "avg_mcc = []\n",
        "list_of_models = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(loo.split(df_train_x)):\n",
        "    mnb = MultinomialNB()\n",
        "    mnb.fit(df_train_x[train_index], df_train_y[train_index])\n",
        "    y_pred_mnb = mnb.predict(df_train_x[test_index])\n",
        "\n",
        "    avg_accuracy.append(accuracy_score(df_train_y[test_index], y_pred_mnb))\n",
        "    avg_mcc.append(matthews_corrcoef(df_train_y[test_index], y_pred_mnb))\n",
        "    list_of_models.append(mnb)\n",
        "\n",
        "max_acc_index = avg_accuracy.index(max(avg_accuracy))\n",
        "y_pred_mnb = list_of_models[max_acc_index].predict(df_test_x)\n",
        "\n",
        "print(\"Test Accuracy score for MultinomialNB on Best LOO\", round(accuracy_score(df_test_y, y_pred_mnb), 3))\n",
        "print(\"Test Precision score for MultinomialNB on Best LOO\", round(precision_score(df_test_y, y_pred_mnb), 3))\n",
        "print(\"Test Recall score for MultinomialNB on Best LOO\", round(recall_score(df_test_y, y_pred_mnb), 3))\n",
        "print(\"MCC score for MultinomialNB on Best LOO\", round(matthews_corrcoef(df_test_y, y_pred_mnb), 3))\n",
        "print()\n",
        "\n",
        "avg_accuracy = []\n",
        "avg_mcc = []\n",
        "list_of_models = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(loo.split(df_train_x)):\n",
        "    sgd = SGDClassifier(random_state=random_seed, loss=\"log_loss\", n_jobs=-1, class_weight=\"balanced\")\n",
        "    sgd.fit(df_train_x[train_index], df_train_y[train_index])\n",
        "    y_pred_sgd = sgd.predict(df_train_x[test_index])\n",
        "\n",
        "    avg_accuracy.append(accuracy_score(df_train_y[test_index], y_pred_sgd))\n",
        "    avg_mcc.append(matthews_corrcoef(df_train_y[test_index], y_pred_sgd))\n",
        "    list_of_models.append(sgd)\n",
        "\n",
        "max_acc_index = avg_accuracy.index(max(avg_accuracy))\n",
        "y_pred_sgd = list_of_models[max_acc_index].predict(df_test_x)\n",
        "\n",
        "print(\"Test Accuracy score for SGDClassifier on Best LOO\", round(accuracy_score(df_test_y, y_pred_sgd), 3))\n",
        "print(\"Test Precision score for SGDClassifier on Best LOO\", round(precision_score(df_test_y, y_pred_sgd), 3))\n",
        "print(\"Test Recall score for SGDClassifier on Best LOO\", round(recall_score(df_test_y, y_pred_sgd), 3))\n",
        "print(\"MCC score for SGDClassifier on Best LOO\", round(matthews_corrcoef(df_test_y, y_pred_sgd), 3))\n",
        "print()\n",
        "\n",
        "avg_accuracy = []\n",
        "avg_mcc = []\n",
        "list_of_models = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(loo.split(df_train_x)):\n",
        "    knn = KNeighborsClassifier(weights=\"distance\", n_jobs=-1)\n",
        "    knn.fit(df_train_x[train_index], df_train_y[train_index])\n",
        "    y_pred_knn = knn.predict(df_train_x[test_index])\n",
        "\n",
        "    avg_accuracy.append(accuracy_score(df_train_y[test_index], y_pred_knn))\n",
        "    avg_mcc.append(matthews_corrcoef(df_train_y[test_index], y_pred_knn))\n",
        "    list_of_models.append(knn)\n",
        "\n",
        "max_acc_index = avg_accuracy.index(max(avg_accuracy))\n",
        "y_pred_knn = list_of_models[max_acc_index].predict(df_test_x)\n",
        "\n",
        "print(\"Test Accuracy score for KNeighborsClassifier on Best LOO\", round(accuracy_score(df_test_y, y_pred_knn), 3))\n",
        "print(\"Test Precision score for KNeighborsClassifier on Best LOO\", round(precision_score(df_test_y, y_pred_knn), 3))\n",
        "print(\"Test Recall score for KNeighborsClassifier on Best LOO\", round(recall_score(df_test_y, y_pred_knn), 3))\n",
        "print(\"MCC score for KNeighborsClassifier on Best LOO\", round(matthews_corrcoef(df_test_y, y_pred_knn), 3))\n",
        "print()\n",
        "\n",
        "avg_accuracy = []\n",
        "avg_mcc = []\n",
        "list_of_models = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(loo.split(df_train_x)):\n",
        "    dtc = DecisionTreeClassifier(random_state=random_seed, criterion=\"entropy\", class_weight=\"balanced\")\n",
        "    dtc.fit(df_train_x[train_index], df_train_y[train_index])\n",
        "    y_pred_dtc = dtc.predict(df_train_x[test_index])\n",
        "\n",
        "    avg_accuracy.append(accuracy_score(df_train_y[test_index], y_pred_dtc))\n",
        "    avg_mcc.append(matthews_corrcoef(df_train_y[test_index], y_pred_dtc))\n",
        "    list_of_models.append(dtc)\n",
        "\n",
        "max_acc_index = avg_accuracy.index(max(avg_accuracy))\n",
        "y_pred_dtc = list_of_models[max_acc_index].predict(df_test_x)\n",
        "\n",
        "print(\"Test Accuracy score for DecisionTreeClassifier on Best LOO\", round(accuracy_score(df_test_y, y_pred_dtc), 3))\n",
        "print(\"Test Precision score for DecisionTreeClassifier on Best LOO\", round(precision_score(df_test_y, y_pred_dtc), 3))\n",
        "print(\"Test Recall score for DecisionTreeClassifier on Best LOO\", round(recall_score(df_test_y, y_pred_dtc), 3))\n",
        "print(\"MCC score for DecisionTreeClassifier on Best LOO\", round(matthews_corrcoef(df_test_y, y_pred_dtc), 3))\n",
        "print()\n",
        "\n",
        "print(\"#######################################################################\")\n",
        "print(\"######################ENSEMBLE BASED LEARNING MODELS##################\")\n",
        "print(\"#######################################################################\")\n",
        "\n",
        "avg_accuracy = []\n",
        "avg_mcc = []\n",
        "list_of_models = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(loo.split(df_train_x)):\n",
        "    rfc = RandomForestClassifier(random_state=random_seed, max_depth=6, n_estimators = 200, n_jobs=-1, class_weight=\"balanced\")\n",
        "    rfc.fit(df_train_x[train_index], df_train_y[train_index])\n",
        "    y_pred_rfc = rfc.predict(df_train_x[test_index])\n",
        "\n",
        "    avg_accuracy.append(accuracy_score(df_train_y[test_index], y_pred_rfc))\n",
        "    avg_mcc.append(matthews_corrcoef(df_train_y[test_index], y_pred_rfc))\n",
        "    list_of_models.append(rfc)\n",
        "\n",
        "max_acc_index = avg_accuracy.index(max(avg_accuracy))\n",
        "y_pred_rfc = list_of_models[max_acc_index].predict(df_test_x)\n",
        "\n",
        "print(\"Test Accuracy score for RandomForestClassifier on Best LOO\", round(accuracy_score(df_test_y, y_pred_rfc), 3))\n",
        "print(\"Test Precision score for RandomForestClassifier on Best LOO\", round(precision_score(df_test_y, y_pred_rfc), 3))\n",
        "print(\"Test Recall score for RandomForestClassifier on Best LOO\", round(recall_score(df_test_y, y_pred_rfc), 3))\n",
        "print(\"MCC score for RandomForestClassifier on Best LOO\", round(matthews_corrcoef(df_test_y, y_pred_rfc), 3))\n",
        "print()\n",
        "\n",
        "avg_accuracy = []\n",
        "avg_mcc = []\n",
        "list_of_models = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(loo.split(df_train_x)):\n",
        "    gbc = GradientBoostingClassifier(random_state=random_seed, max_depth=6, n_estimators = 200)\n",
        "    gbc.fit(df_train_x[train_index], df_train_y[train_index])\n",
        "    y_pred_gbc = gbc.predict(df_train_x[test_index])\n",
        "\n",
        "    avg_accuracy.append(accuracy_score(df_train_y[test_index], y_pred_gbc))\n",
        "    avg_mcc.append(matthews_corrcoef(df_train_y[test_index], y_pred_gbc))\n",
        "    list_of_models.append(gbc)\n",
        "\n",
        "max_acc_index = avg_accuracy.index(max(avg_accuracy))\n",
        "y_pred_gbc = list_of_models[max_acc_index].predict(df_test_x)\n",
        "\n",
        "print(\"Test Accuracy score for GradientBoostingClassifier on Best LOO\", round(accuracy_score(df_test_y, y_pred_gbc), 3))\n",
        "print(\"Test Precision score for GradientBoostingClassifier on Best LOO\", round(precision_score(df_test_y, y_pred_gbc), 3))\n",
        "print(\"Test Recall score for GradientBoostingClassifier on Best LOO\", round(recall_score(df_test_y, y_pred_gbc), 3))\n",
        "print(\"MCC score for GradientBoostingClassifier on Best LOO\", round(matthews_corrcoef(df_test_y, y_pred_gbc), 3))\n",
        "print()\n",
        "\n",
        "avg_accuracy = []\n",
        "avg_mcc = []\n",
        "list_of_models = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(loo.split(df_train_x)):\n",
        "    xgb = XGBClassifier(random_state=random_seed, max_depth=7, n_estimators = 200)\n",
        "    xgb.fit(df_train_x[train_index], df_train_y[train_index])\n",
        "    y_pred_xgb = xgb.predict(df_train_x[test_index])\n",
        "\n",
        "    avg_accuracy.append(accuracy_score(df_train_y[test_index], y_pred_xgb))\n",
        "    avg_mcc.append(matthews_corrcoef(df_train_y[test_index], y_pred_xgb))\n",
        "    list_of_models.append(xgb)\n",
        "\n",
        "max_acc_index = avg_accuracy.index(max(avg_accuracy))\n",
        "y_pred_xgb = list_of_models[max_acc_index].predict(df_test_x)\n",
        "\n",
        "print(\"Test Accuracy score for XGBClassifier on Best LOO\", round(accuracy_score(df_test_y, y_pred_xgb), 3))\n",
        "print(\"Test Precision score for XGBClassifier on Best LOO\", round(precision_score(df_test_y, y_pred_xgb), 3))\n",
        "print(\"Test Recall score for XGBClassifier on Best LOO\", round(recall_score(df_test_y, y_pred_xgb), 3))\n",
        "print(\"MCC score for XGBClassifier on Best LOO\", round(matthews_corrcoef(df_test_y, y_pred_xgb), 3))\n",
        "print()\n",
        "\n",
        "\n",
        "avg_accuracy = []\n",
        "avg_mcc = []\n",
        "list_of_models = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(loo.split(df_train_x)):\n",
        "    adgb = AdaBoostClassifier(random_state=random_seed, n_estimators = 200)\n",
        "    adgb.fit(df_train_x[train_index], df_train_y[train_index])\n",
        "    y_pred_adgb = adgb.predict(df_train_x[test_index])\n",
        "\n",
        "    avg_accuracy.append(accuracy_score(df_train_y[test_index], y_pred_adgb))\n",
        "    avg_mcc.append(matthews_corrcoef(df_train_y[test_index], y_pred_adgb))\n",
        "    list_of_models.append(xgb)\n",
        "\n",
        "max_acc_index = avg_accuracy.index(max(avg_accuracy))\n",
        "y_pred_adgb = list_of_models[max_acc_index].predict(df_test_x)\n",
        "\n",
        "print(\"Test Accuracy score for AdaBoostClassifier on Best LOO\", round(accuracy_score(df_test_y, y_pred_adgb), 3))\n",
        "print(\"Test Precision score for AdaBoostClassifier on Best LOO\", round(precision_score(df_test_y, y_pred_adgb), 3))\n",
        "print(\"Test Recall score for AdaBoostClassifier on Best LOO\", round(recall_score(df_test_y, y_pred_adgb), 3))\n",
        "print(\"MCC score for AdaBoostClassifier on Best LOO\", round(matthews_corrcoef(df_test_y, y_pred_adgb), 3))\n",
        "print()\n",
        "\n",
        "avg_accuracy = []\n",
        "avg_mcc = []\n",
        "list_of_models = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(loo.split(df_train_x)):\n",
        "    lgbm_c = lgb.LGBMClassifier(random_state=random_seed, n_estimators = 200, n_jobs=-1)\n",
        "    lgbm_c.fit(df_train_x[train_index], df_train_y[train_index])\n",
        "    y_pred_lgbm_c = lgbm_c.predict(df_train_x[test_index])\n",
        "\n",
        "    avg_accuracy.append(accuracy_score(df_train_y[test_index], y_pred_lgbm_c))\n",
        "    avg_mcc.append(matthews_corrcoef(df_train_y[test_index], y_pred_lgbm_c))\n",
        "    list_of_models.append(xgb)\n",
        "\n",
        "max_acc_index = avg_accuracy.index(max(avg_accuracy))\n",
        "y_pred_lgbm_c = list_of_models[max_acc_index].predict(df_test_x)\n",
        "\n",
        "print(\"Test Accuracy score for LGBMClassifier on Best LOO\", round(accuracy_score(df_test_y, y_pred_lgbm_c), 3))\n",
        "print(\"Test Precision score for LGBMClassifier on Best LOO\", round(precision_score(df_test_y, y_pred_lgbm_c), 3))\n",
        "print(\"Test Recall score for LGBMClassifier on Best LOO\", round(recall_score(df_test_y, y_pred_lgbm_c), 3))\n",
        "print(\"MCC score for LGBMClassifier on Best LOO\", round(matthews_corrcoef(df_test_y, y_pred_lgbm_c), 3))\n",
        "print()\n",
        "\n",
        "\n",
        "avg_accuracy = []\n",
        "avg_mcc = []\n",
        "list_of_models = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(loo.split(df_train_x)):\n",
        "#     lr = LogisticRegression(random_state=random_seed)\n",
        "#     svc = SVC(random_state=random_seed, degree=25)\n",
        "#     gnb = GaussianNB()\n",
        "#     xgb = XGBClassifier(random_state=random_seed)\n",
        "#     eclf1 = VotingClassifier(estimators=[('lr', lr), ('svc', svc), ('gnb', gnb), ('xgb', xgb)], voting='hard')\n",
        "    gbc = GradientBoostingClassifier(random_state=random_seed, max_depth=6, n_estimators = 200)\n",
        "    dgb = AdaBoostClassifier(random_state=random_seed, n_estimators = 200)\n",
        "    xgb = XGBClassifier(random_state=random_seed, max_depth=7, n_estimators = 200)\n",
        "    eclf1 = VotingClassifier(estimators=[('gbc', gbc), ('adgb', adgb), ('xgb', xgb)], voting='hard')\n",
        "    \n",
        "    eclf1 = eclf1.fit(df_train_x[train_index], df_train_y[train_index])\n",
        "    y_pred_eclf1 = eclf1.predict(df_train_x[test_index])\n",
        "\n",
        "    avg_accuracy.append(accuracy_score(df_train_y[test_index], y_pred_eclf1))\n",
        "    avg_mcc.append(matthews_corrcoef(df_train_y[test_index], y_pred_eclf1))\n",
        "    list_of_models.append(eclf1)\n",
        "\n",
        "max_acc_index = avg_accuracy.index(max(avg_accuracy))\n",
        "y_pred_eclf1 = list_of_models[max_acc_index].predict(df_test_x)\n",
        "\n",
        "print(\"Test Accuracy score for VotingClassifier on Best LOO\", round(accuracy_score(df_test_y, y_pred_eclf1), 3))\n",
        "print(\"Test Precision score for VotingClassifier on Best LOO\", round(precision_score(df_test_y, y_pred_eclf1), 3))\n",
        "print(\"Test Recall score for VotingClassifier on Best LOO\", round(recall_score(df_test_y, y_pred_eclf1), 3))\n",
        "print(\"MCC score for VotingClassifier on Best LOO\", round(matthews_corrcoef(df_test_y, y_pred_eclf1), 3))\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Monte Carlo Implementation"
      ],
      "metadata": {
        "id": "kLiYolZkVLBF"
      },
      "id": "kLiYolZkVLBF"
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "id": "2c9cfab9",
      "metadata": {
        "id": "2c9cfab9"
      },
      "outputs": [],
      "source": [
        "rs = ShuffleSplit(n_splits=15, test_size=.25, random_state=random_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "d671b825",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d671b825",
        "outputId": "24531559-86f9-41e0-dca4-f7d51a75df20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#######################################################################\n",
            "######################STANDALONE MACHINE LEARNING MODELS###############\n",
            "#######################################################################\n",
            "Test Accuracy score for LogisticRegression on Best MonteCarlo 0.611\n",
            "Test Precision score for LogisticRegression on Best MonteCarlo 0.417\n",
            "Test Recall score for LogisticRegression on Best MonteCarlo 1.0\n",
            "MCC score for LogisticRegression on Best MonteCarlo 0.439\n",
            "\n",
            "Test Accuracy score for SVC on Best MonteCarlo 0.667\n",
            "Test Precision score for SVC on Best MonteCarlo 0.444\n",
            "Test Recall score for SVC on Best MonteCarlo 0.8\n",
            "MCC score for SVC on Best MonteCarlo 0.372\n",
            "\n",
            "Test Accuracy score for GaussianNB on Best MonteCarlo 0.333\n",
            "Test Precision score for GaussianNB on Best MonteCarlo 0.294\n",
            "Test Recall score for GaussianNB on Best MonteCarlo 1.0\n",
            "MCC score for GaussianNB on Best MonteCarlo 0.15\n",
            "\n",
            "Test Accuracy score for MultinomialNB on Best MonteCarlo 0.556\n",
            "Test Precision score for MultinomialNB on Best MonteCarlo 0.385\n",
            "Test Recall score for MultinomialNB on Best MonteCarlo 1.0\n",
            "MCC score for MultinomialNB on Best MonteCarlo 0.385\n",
            "\n",
            "Test Accuracy score for SGDClassifier on Best MonteCarlo 0.611\n",
            "Test Precision score for SGDClassifier on Best MonteCarlo 0.417\n",
            "Test Recall score for SGDClassifier on Best MonteCarlo 1.0\n",
            "MCC score for SGDClassifier on Best MonteCarlo 0.439\n",
            "\n",
            "Test Accuracy score for KNeighborsClassifier on Best MonteCarlo 0.5\n",
            "Test Precision score for KNeighborsClassifier on Best MonteCarlo 0.333\n",
            "Test Recall score for KNeighborsClassifier on Best MonteCarlo 0.8\n",
            "MCC score for KNeighborsClassifier on Best MonteCarlo 0.175\n",
            "\n",
            "Test Accuracy score for DecisionTreeClassifier on Best MonteCarlo 0.556\n",
            "Test Precision score for DecisionTreeClassifier on Best MonteCarlo 0.385\n",
            "Test Recall score for DecisionTreeClassifier on Best MonteCarlo 1.0\n",
            "MCC score for DecisionTreeClassifier on Best MonteCarlo 0.385\n",
            "\n",
            "#######################################################################\n",
            "######################ENSEMBLE BASED LEARNING MODELS##################\n",
            "#######################################################################\n",
            "Test Accuracy score for RandomForestClassifier on Best MonteCarlo 0.833\n",
            "Test Precision score for RandomForestClassifier on Best MonteCarlo 0.75\n",
            "Test Recall score for RandomForestClassifier on Best MonteCarlo 0.6\n",
            "MCC score for RandomForestClassifier on Best MonteCarlo 0.564\n",
            "\n",
            "Test Accuracy score for GradientBoostingClassifier on Best MonteCarlo 0.833\n",
            "Test Precision score for GradientBoostingClassifier on Best MonteCarlo 1.0\n",
            "Test Recall score for GradientBoostingClassifier on Best MonteCarlo 0.4\n",
            "MCC score for GradientBoostingClassifier on Best MonteCarlo 0.57\n",
            "\n",
            "Test Accuracy score for XGBClassifier on Best MonteCarlo 0.778\n",
            "Test Precision score for XGBClassifier on Best MonteCarlo 0.556\n",
            "Test Recall score for XGBClassifier on Best MonteCarlo 1.0\n",
            "MCC score for XGBClassifier on Best MonteCarlo 0.62\n",
            "\n",
            "Test Accuracy score for AdaBoostClassifier on Best MonteCarlo 0.889\n",
            "Test Precision score for AdaBoostClassifier on Best MonteCarlo 0.714\n",
            "Test Recall score for AdaBoostClassifier on Best MonteCarlo 1.0\n",
            "MCC score for AdaBoostClassifier on Best MonteCarlo 0.777\n",
            "\n",
            "Test Accuracy score for LGBMClassifier on Best MonteCarlo 0.889\n",
            "Test Precision score for LGBMClassifier on Best MonteCarlo 0.714\n",
            "Test Recall score for LGBMClassifier on Best MonteCarlo 1.0\n",
            "MCC score for LGBMClassifier on Best MonteCarlo 0.777\n",
            "\n",
            "Test Accuracy score for VotingClassifier on Best MonteCarlo 0.778\n",
            "Test Precision score for VotingClassifier on Best MonteCarlo 0.571\n",
            "Test Recall score for VotingClassifier on Best MonteCarlo 0.8\n",
            "MCC score for VotingClassifier on Best MonteCarlo 0.523\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"#######################################################################\")\n",
        "print(\"######################STANDALONE MACHINE LEARNING MODELS###############\")\n",
        "print(\"#######################################################################\")\n",
        "\n",
        "\n",
        "avg_accuracy = []\n",
        "avg_mcc = []\n",
        "list_of_models = []\n",
        "for i, (train_index, test_index) in enumerate(rs.split(df_train_x)):\n",
        "    lr = LogisticRegression(random_state=random_seed, class_weight=\"balanced\")\n",
        "    lr.fit(df_train_x[train_index], df_train_y[train_index])\n",
        "    y_pred_lr = lr.predict(df_train_x[test_index])\n",
        "\n",
        "    avg_accuracy.append(accuracy_score(df_train_y[test_index], y_pred_lr))\n",
        "    avg_mcc.append(matthews_corrcoef(df_train_y[test_index], y_pred_lr))\n",
        "    list_of_models.append(lr)\n",
        "\n",
        "max_acc_index = avg_accuracy.index(max(avg_accuracy))\n",
        "y_pred_lr = list_of_models[max_acc_index].predict(df_test_x)\n",
        "print(\"Test Accuracy score for LogisticRegression on Best MonteCarlo\", round(accuracy_score(df_test_y, y_pred_lr), 3))\n",
        "print(\"Test Precision score for LogisticRegression on Best MonteCarlo\", round(precision_score(df_test_y, y_pred_lr), 3))\n",
        "print(\"Test Recall score for LogisticRegression on Best MonteCarlo\", round(recall_score(df_test_y, y_pred_lr), 3))\n",
        "print(\"MCC score for LogisticRegression on Best MonteCarlo\", round(matthews_corrcoef(df_test_y, y_pred_lr), 3))\n",
        "print()\n",
        "\n",
        "avg_accuracy = []\n",
        "avg_mcc = []\n",
        "list_of_models = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(rs.split(df_train_x)):\n",
        "    svc = SVC(random_state=random_seed, degree=25, class_weight=\"balanced\")\n",
        "    svc.fit(df_train_x[train_index], df_train_y[train_index])\n",
        "    y_pred_svc = svc.predict(df_train_x[test_index])\n",
        "\n",
        "    avg_accuracy.append(accuracy_score(df_train_y[test_index], y_pred_svc))\n",
        "    avg_mcc.append(matthews_corrcoef(df_train_y[test_index], y_pred_svc))\n",
        "    list_of_models.append(svc)\n",
        "\n",
        "max_acc_index = avg_accuracy.index(max(avg_accuracy))\n",
        "y_pred_svc = list_of_models[max_acc_index].predict(df_test_x)\n",
        "print(\"Test Accuracy score for SVC on Best MonteCarlo\", round(accuracy_score(df_test_y, y_pred_svc), 3))\n",
        "print(\"Test Precision score for SVC on Best MonteCarlo\", round(precision_score(df_test_y, y_pred_svc), 3))\n",
        "print(\"Test Recall score for SVC on Best MonteCarlo\", round(recall_score(df_test_y, y_pred_svc), 3))\n",
        "print(\"MCC score for SVC on Best MonteCarlo\", round(matthews_corrcoef(df_test_y, y_pred_svc), 3))\n",
        "print()\n",
        "\n",
        "avg_accuracy = []\n",
        "avg_mcc = []\n",
        "list_of_models = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(rs.split(df_train_x)):\n",
        "    gnb = GaussianNB()\n",
        "    gnb.fit(df_train_x[train_index], df_train_y[train_index])\n",
        "    y_pred_gnb = gnb.predict(df_train_x[test_index])\n",
        "\n",
        "    avg_accuracy.append(accuracy_score(df_train_y[test_index], y_pred_gnb))\n",
        "    avg_mcc.append(matthews_corrcoef(df_train_y[test_index], y_pred_gnb))\n",
        "    list_of_models.append(gnb)\n",
        "\n",
        "max_acc_index = avg_accuracy.index(max(avg_accuracy))\n",
        "y_pred_gnb = list_of_models[max_acc_index].predict(df_test_x)\n",
        "\n",
        "print(\"Test Accuracy score for GaussianNB on Best MonteCarlo\", round(accuracy_score(df_test_y, y_pred_gnb), 3))\n",
        "print(\"Test Precision score for GaussianNB on Best MonteCarlo\", round(precision_score(df_test_y, y_pred_gnb), 3))\n",
        "print(\"Test Recall score for GaussianNB on Best MonteCarlo\", round(recall_score(df_test_y, y_pred_gnb), 3))\n",
        "print(\"MCC score for GaussianNB on Best MonteCarlo\", round(matthews_corrcoef(df_test_y, y_pred_gnb), 3))\n",
        "print()\n",
        "\n",
        "avg_accuracy = []\n",
        "avg_mcc = []\n",
        "list_of_models = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(rs.split(df_train_x)):\n",
        "    mnb = MultinomialNB()\n",
        "    mnb.fit(df_train_x[train_index], df_train_y[train_index])\n",
        "    y_pred_mnb = mnb.predict(df_train_x[test_index])\n",
        "\n",
        "    avg_accuracy.append(accuracy_score(df_train_y[test_index], y_pred_mnb))\n",
        "    avg_mcc.append(matthews_corrcoef(df_train_y[test_index], y_pred_mnb))\n",
        "    list_of_models.append(mnb)\n",
        "\n",
        "max_acc_index = avg_accuracy.index(max(avg_accuracy))\n",
        "y_pred_mnb = list_of_models[max_acc_index].predict(df_test_x)\n",
        "\n",
        "print(\"Test Accuracy score for MultinomialNB on Best MonteCarlo\", round(accuracy_score(df_test_y, y_pred_mnb), 3))\n",
        "print(\"Test Precision score for MultinomialNB on Best MonteCarlo\", round(precision_score(df_test_y, y_pred_mnb), 3))\n",
        "print(\"Test Recall score for MultinomialNB on Best MonteCarlo\", round(recall_score(df_test_y, y_pred_mnb), 3))\n",
        "print(\"MCC score for MultinomialNB on Best MonteCarlo\", round(matthews_corrcoef(df_test_y, y_pred_mnb), 3))\n",
        "print()\n",
        "\n",
        "avg_accuracy = []\n",
        "avg_mcc = []\n",
        "list_of_models = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(rs.split(df_train_x)):\n",
        "    sgd = SGDClassifier(random_state=random_seed, loss=\"log_loss\", n_jobs=-1, class_weight=\"balanced\")\n",
        "    sgd.fit(df_train_x[train_index], df_train_y[train_index])\n",
        "    y_pred_sgd = sgd.predict(df_train_x[test_index])\n",
        "\n",
        "    avg_accuracy.append(accuracy_score(df_train_y[test_index], y_pred_sgd))\n",
        "    avg_mcc.append(matthews_corrcoef(df_train_y[test_index], y_pred_sgd))\n",
        "    list_of_models.append(sgd)\n",
        "\n",
        "max_acc_index = avg_accuracy.index(max(avg_accuracy))\n",
        "y_pred_sgd = list_of_models[max_acc_index].predict(df_test_x)\n",
        "\n",
        "print(\"Test Accuracy score for SGDClassifier on Best MonteCarlo\", round(accuracy_score(df_test_y, y_pred_sgd), 3))\n",
        "print(\"Test Precision score for SGDClassifier on Best MonteCarlo\", round(precision_score(df_test_y, y_pred_sgd), 3))\n",
        "print(\"Test Recall score for SGDClassifier on Best MonteCarlo\", round(recall_score(df_test_y, y_pred_sgd), 3))\n",
        "print(\"MCC score for SGDClassifier on Best MonteCarlo\", round(matthews_corrcoef(df_test_y, y_pred_sgd), 3))\n",
        "print()\n",
        "\n",
        "avg_accuracy = []\n",
        "avg_mcc = []\n",
        "list_of_models = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(rs.split(df_train_x)):\n",
        "    knn = KNeighborsClassifier(weights=\"distance\", n_jobs=-1)\n",
        "    knn.fit(df_train_x[train_index], df_train_y[train_index])\n",
        "    y_pred_knn = knn.predict(df_train_x[test_index])\n",
        "\n",
        "    avg_accuracy.append(accuracy_score(df_train_y[test_index], y_pred_knn))\n",
        "    avg_mcc.append(matthews_corrcoef(df_train_y[test_index], y_pred_knn))\n",
        "    list_of_models.append(knn)\n",
        "\n",
        "max_acc_index = avg_accuracy.index(max(avg_accuracy))\n",
        "y_pred_knn = list_of_models[max_acc_index].predict(df_test_x)\n",
        "\n",
        "print(\"Test Accuracy score for KNeighborsClassifier on Best MonteCarlo\", round(accuracy_score(df_test_y, y_pred_knn), 3))\n",
        "print(\"Test Precision score for KNeighborsClassifier on Best MonteCarlo\",round(precision_score(df_test_y, y_pred_knn), 3))\n",
        "print(\"Test Recall score for KNeighborsClassifier on Best MonteCarlo\", round(recall_score(df_test_y, y_pred_knn), 3))\n",
        "print(\"MCC score for KNeighborsClassifier on Best MonteCarlo\", round(matthews_corrcoef(df_test_y, y_pred_knn), 3))\n",
        "print()\n",
        "\n",
        "avg_accuracy = []\n",
        "avg_mcc = []\n",
        "list_of_models = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(rs.split(df_train_x)):\n",
        "    dtc = DecisionTreeClassifier(random_state=random_seed, criterion=\"entropy\", class_weight=\"balanced\")\n",
        "    dtc.fit(df_train_x[train_index], df_train_y[train_index])\n",
        "    y_pred_dtc = dtc.predict(df_train_x[test_index])\n",
        "\n",
        "    avg_accuracy.append(accuracy_score(df_train_y[test_index], y_pred_dtc))\n",
        "    avg_mcc.append(matthews_corrcoef(df_train_y[test_index], y_pred_dtc))\n",
        "    list_of_models.append(dtc)\n",
        "\n",
        "max_acc_index = avg_accuracy.index(max(avg_accuracy))\n",
        "y_pred_dtc = list_of_models[max_acc_index].predict(df_test_x)\n",
        "\n",
        "print(\"Test Accuracy score for DecisionTreeClassifier on Best MonteCarlo\", round(accuracy_score(df_test_y, y_pred_dtc), 3))\n",
        "print(\"Test Precision score for DecisionTreeClassifier on Best MonteCarlo\", round(precision_score(df_test_y, y_pred_dtc), 3))\n",
        "print(\"Test Recall score for DecisionTreeClassifier on Best MonteCarlo\", round(recall_score(df_test_y, y_pred_dtc), 3))\n",
        "print(\"MCC score for DecisionTreeClassifier on Best MonteCarlo\", round(matthews_corrcoef(df_test_y, y_pred_dtc), 3))\n",
        "print()\n",
        "\n",
        "print(\"#######################################################################\")\n",
        "print(\"######################ENSEMBLE BASED LEARNING MODELS##################\")\n",
        "print(\"#######################################################################\")\n",
        "\n",
        "\n",
        "avg_accuracy = []\n",
        "avg_mcc = []\n",
        "list_of_models = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(rs.split(df_train_x)):\n",
        "    rfc = RandomForestClassifier(random_state=random_seed, max_depth=6, n_estimators = 200, n_jobs=-1, class_weight=\"balanced\")\n",
        "    rfc.fit(df_train_x[train_index], df_train_y[train_index])\n",
        "    y_pred_rfc = rfc.predict(df_train_x[test_index])\n",
        "\n",
        "    avg_accuracy.append(accuracy_score(df_train_y[test_index], y_pred_rfc))\n",
        "    avg_mcc.append(matthews_corrcoef(df_train_y[test_index], y_pred_rfc))\n",
        "    list_of_models.append(rfc)\n",
        "\n",
        "max_acc_index = avg_accuracy.index(max(avg_accuracy))\n",
        "y_pred_rfc = list_of_models[max_acc_index].predict(df_test_x)\n",
        "\n",
        "print(\"Test Accuracy score for RandomForestClassifier on Best MonteCarlo\", round(accuracy_score(df_test_y, y_pred_rfc), 3))\n",
        "print(\"Test Precision score for RandomForestClassifier on Best MonteCarlo\", round(precision_score(df_test_y, y_pred_rfc), 3))\n",
        "print(\"Test Recall score for RandomForestClassifier on Best MonteCarlo\", round(recall_score(df_test_y, y_pred_rfc), 3))\n",
        "print(\"MCC score for RandomForestClassifier on Best MonteCarlo\", round(matthews_corrcoef(df_test_y, y_pred_rfc), 3))\n",
        "print()\n",
        "\n",
        "avg_accuracy = []\n",
        "avg_mcc = []\n",
        "list_of_models = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(rs.split(df_train_x)):\n",
        "    gbc = GradientBoostingClassifier(random_state=random_seed, max_depth=6, n_estimators = 200)\n",
        "    gbc.fit(df_train_x[train_index], df_train_y[train_index])\n",
        "    y_pred_gbc = gbc.predict(df_train_x[test_index])\n",
        "\n",
        "    avg_accuracy.append(accuracy_score(df_train_y[test_index], y_pred_gbc))\n",
        "    avg_mcc.append(matthews_corrcoef(df_train_y[test_index], y_pred_gbc))\n",
        "    list_of_models.append(gbc)\n",
        "\n",
        "max_acc_index = avg_accuracy.index(max(avg_accuracy))\n",
        "y_pred_gbc = list_of_models[max_acc_index].predict(df_test_x)\n",
        "\n",
        "print(\"Test Accuracy score for GradientBoostingClassifier on Best MonteCarlo\", round(accuracy_score(df_test_y, y_pred_gbc), 3))\n",
        "print(\"Test Precision score for GradientBoostingClassifier on Best MonteCarlo\", round(precision_score(df_test_y, y_pred_gbc), 3))\n",
        "print(\"Test Recall score for GradientBoostingClassifier on Best MonteCarlo\", round(recall_score(df_test_y, y_pred_gbc), 3))\n",
        "print(\"MCC score for GradientBoostingClassifier on Best MonteCarlo\", round(matthews_corrcoef(df_test_y, y_pred_gbc), 3))\n",
        "print()\n",
        "\n",
        "avg_accuracy = []\n",
        "avg_mcc = []\n",
        "list_of_models = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(rs.split(df_train_x)):\n",
        "    xgb = XGBClassifier(random_state=random_seed, max_depth=7, n_estimators = 200)\n",
        "    xgb.fit(df_train_x[train_index], df_train_y[train_index])\n",
        "    y_pred_xgb = xgb.predict(df_train_x[test_index])\n",
        "\n",
        "    avg_accuracy.append(accuracy_score(df_train_y[test_index], y_pred_xgb))\n",
        "    avg_mcc.append(matthews_corrcoef(df_train_y[test_index], y_pred_xgb))\n",
        "    list_of_models.append(xgb)\n",
        "\n",
        "max_acc_index = avg_accuracy.index(max(avg_accuracy))\n",
        "y_pred_xgb = list_of_models[max_acc_index].predict(df_test_x)\n",
        "\n",
        "print(\"Test Accuracy score for XGBClassifier on Best MonteCarlo\", round(accuracy_score(df_test_y, y_pred_xgb), 3))\n",
        "print(\"Test Precision score for XGBClassifier on Best MonteCarlo\", round(precision_score(df_test_y, y_pred_xgb), 3))\n",
        "print(\"Test Recall score for XGBClassifier on Best MonteCarlo\", round(recall_score(df_test_y, y_pred_xgb), 3))\n",
        "print(\"MCC score for XGBClassifier on Best MonteCarlo\", round(matthews_corrcoef(df_test_y, y_pred_xgb), 3))\n",
        "print()\n",
        "\n",
        "\n",
        "avg_accuracy = []\n",
        "avg_mcc = []\n",
        "list_of_models = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(rs.split(df_train_x)):\n",
        "    adgb = AdaBoostClassifier(random_state=random_seed, n_estimators = 200)\n",
        "    adgb.fit(df_train_x[train_index], df_train_y[train_index])\n",
        "    y_pred_adgb = adgb.predict(df_train_x[test_index])\n",
        "\n",
        "    avg_accuracy.append(accuracy_score(df_train_y[test_index], y_pred_adgb))\n",
        "    avg_mcc.append(matthews_corrcoef(df_train_y[test_index], y_pred_adgb))\n",
        "    list_of_models.append(xgb)\n",
        "\n",
        "max_acc_index = avg_accuracy.index(max(avg_accuracy))\n",
        "y_pred_adgb = list_of_models[max_acc_index].predict(df_test_x)\n",
        "\n",
        "print(\"Test Accuracy score for AdaBoostClassifier on Best MonteCarlo\", round(accuracy_score(df_test_y, y_pred_adgb), 3))\n",
        "print(\"Test Precision score for AdaBoostClassifier on Best MonteCarlo\", round(precision_score(df_test_y, y_pred_adgb), 3))\n",
        "print(\"Test Recall score for AdaBoostClassifier on Best MonteCarlo\", round(recall_score(df_test_y, y_pred_adgb), 3))\n",
        "print(\"MCC score for AdaBoostClassifier on Best MonteCarlo\", round(matthews_corrcoef(df_test_y, y_pred_adgb), 3))\n",
        "print()\n",
        "\n",
        "avg_accuracy = []\n",
        "avg_mcc = []\n",
        "list_of_models = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(rs.split(df_train_x)):\n",
        "    lgbm_c = lgb.LGBMClassifier(random_state=random_seed, n_estimators = 200, n_jobs=-1)\n",
        "    lgbm_c.fit(df_train_x[train_index], df_train_y[train_index])\n",
        "    y_pred_lgbm_c = lgbm_c.predict(df_train_x[test_index])\n",
        "\n",
        "    avg_accuracy.append(accuracy_score(df_train_y[test_index], y_pred_lgbm_c))\n",
        "    avg_mcc.append(matthews_corrcoef(df_train_y[test_index], y_pred_lgbm_c))\n",
        "    list_of_models.append(xgb)\n",
        "\n",
        "max_acc_index = avg_accuracy.index(max(avg_accuracy))\n",
        "y_pred_lgbm_c = list_of_models[max_acc_index].predict(df_test_x)\n",
        "\n",
        "print(\"Test Accuracy score for LGBMClassifier on Best MonteCarlo\", round(accuracy_score(df_test_y, y_pred_lgbm_c), 3))\n",
        "print(\"Test Precision score for LGBMClassifier on Best MonteCarlo\", round(precision_score(df_test_y, y_pred_lgbm_c), 3))\n",
        "print(\"Test Recall score for LGBMClassifier on Best MonteCarlo\", round(recall_score(df_test_y, y_pred_lgbm_c), 3))\n",
        "print(\"MCC score for LGBMClassifier on Best MonteCarlo\", round(matthews_corrcoef(df_test_y, y_pred_lgbm_c), 3))\n",
        "print()\n",
        "\n",
        "\n",
        "avg_accuracy = []\n",
        "avg_mcc = []\n",
        "list_of_models = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(rs.split(df_train_x)):\n",
        "#     lr = LogisticRegression(random_state=random_seed)\n",
        "#     svc = SVC(random_state=random_seed, degree=25)\n",
        "#     gnb = GaussianNB()\n",
        "#     xgb = XGBClassifier(random_state=random_seed)\n",
        "#     eclf1 = VotingClassifier(estimators=[('lr', lr), ('svc', svc), ('gnb', gnb), ('xgb', xgb)], voting='hard')\n",
        "    gbc = GradientBoostingClassifier(random_state=random_seed, max_depth=6, n_estimators = 200)\n",
        "    dgb = AdaBoostClassifier(random_state=random_seed, n_estimators = 200)\n",
        "    xgb = XGBClassifier(random_state=random_seed, max_depth=7, n_estimators = 200)\n",
        "    eclf1 = VotingClassifier(estimators=[('gbc', gbc), ('adgb', adgb), ('xgb', xgb)], voting='hard')\n",
        "    \n",
        "    eclf1 = eclf1.fit(df_train_x[train_index], df_train_y[train_index])\n",
        "    y_pred_eclf1 = eclf1.predict(df_train_x[test_index])\n",
        "\n",
        "    avg_accuracy.append(accuracy_score(df_train_y[test_index], y_pred_eclf1))\n",
        "    avg_mcc.append(matthews_corrcoef(df_train_y[test_index], y_pred_eclf1))\n",
        "    list_of_models.append(eclf1)\n",
        "\n",
        "max_acc_index = avg_accuracy.index(max(avg_accuracy))\n",
        "y_pred_eclf1 = list_of_models[max_acc_index].predict(df_test_x)\n",
        "\n",
        "print(\"Test Accuracy score for VotingClassifier on Best MonteCarlo\", round(accuracy_score(df_test_y, y_pred_eclf1), 3))\n",
        "print(\"Test Precision score for VotingClassifier on Best MonteCarlo\", round(precision_score(df_test_y, y_pred_eclf1), 3))\n",
        "print(\"Test Recall score for VotingClassifier on Best MonteCarlo\", round(recall_score(df_test_y, y_pred_eclf1), 3))\n",
        "print(\"MCC score for VotingClassifier on Best MonteCarlo\", round(matthews_corrcoef(df_test_y, y_pred_eclf1), 3))\n",
        "print()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "b70f485d",
      "metadata": {
        "id": "b70f485d"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}